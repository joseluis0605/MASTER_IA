{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:52:32.738528Z",
     "start_time": "2025-04-06T20:52:28.538586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Configuración de la base de datos SQLite\n",
    "DB_NAME = \"asistente_hospital.db\"\n",
    "\n",
    "\n",
    "# Función para conectar a la base de datos SQLite\n",
    "def conectar_db():\n",
    "    conexion = sqlite3.connect(DB_NAME)\n",
    "    return conexion\n",
    "\n",
    "\n",
    "# Función para crear la tabla de consultas y respuestas en la base de datos\n",
    "def crear_base_datos():\n",
    "    conexion = conectar_db()\n",
    "    cursor = conexion.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS consultas_respuestas (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            consulta TEXT,\n",
    "            respuesta TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    conexion.commit()\n",
    "    cursor.close()\n",
    "    conexion.close()\n",
    "\n",
    "\n",
    "# Función para insertar una consulta y respuesta en la base de datos\n",
    "def insertar_consulta_respuesta(consulta, respuesta):\n",
    "    conexion = conectar_db()\n",
    "    cursor = conexion.cursor()\n",
    "    cursor.execute(\"INSERT INTO consultas_respuestas (consulta, respuesta) VALUES (?, ?)\", (consulta, respuesta))\n",
    "    conexion.commit()\n",
    "    cursor.close()\n",
    "    conexion.close()"
   ],
   "id": "4aa89114f1d55025",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T20:53:25.109974Z",
     "start_time": "2025-04-06T20:52:32.741776Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# Configurar reconocimiento de voz\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Configurar síntesis de voz\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)  # Velocidad de habla\n",
    "engine.setProperty('volume', 1)  # Volumen\n",
    "\n",
    "# Configurar el modelo de Transformers\n",
    "_model_name = \"ITG/DialoGPT-medium-spanish-chitchat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(_model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(_model_name)\n",
    "\n",
    "# Función para generar respuestas\n",
    "def generate_response(user_input, chat_history_ids=None):\n",
    "    # Codificar la entrada\n",
    "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n",
    "\n",
    "    # Generar respuesta con el modelo\n",
    "    chat_history_ids = model.generate(bot_input_ids,\n",
    "                                      max_length=150,  # Limitar el tamaño de la respuesta\n",
    "                                      num_return_sequences=1,  # Solo devolver una respuesta\n",
    "                                      no_repeat_ngram_size=2,  # Evitar repeticiones en la respuesta\n",
    "                                      top_p=0.95,  # Controlar la diversidad de la respuesta\n",
    "                                      top_k=50,  # Controlar la diversidad de la respuesta\n",
    "                                      pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    return response, chat_history_ids\n",
    "\n",
    "\n",
    "# Función para escuchar el comando del usuario\n",
    "def listen_command():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Escuchando...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio, language='es-ES')\n",
    "            print(\"Tú: \" + command)\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"No te entendí. Por favor, repite.\")\n",
    "            return None\n",
    "        except sr.RequestError:\n",
    "            print(\"No se pudo obtener resultados del servicio de Google Speech Recognition\")\n",
    "            return None\n",
    "\n",
    "# Función para hablar\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Función principal del asistente de voz\n",
    "def voice_assistant():\n",
    "    print(\"¡Hola! Soy tu asistente de voz. (di 'adiós' para terminar la conversación)\")\n",
    "    chat_history_ids = None\n",
    "    while True:\n",
    "        command = listen_command()\n",
    "        if command is None:\n",
    "            continue\n",
    "        if command.lower() in [\"adiós\", \"chao\", \"hasta luego\"]:\n",
    "            speak(\"¡Hasta luego!\")\n",
    "            break\n",
    "    \n",
    "        response, chat_history_ids = generate_response(command, chat_history_ids)\n",
    "        print(\"Asistente:\", response)\n",
    "        speak(response)\n",
    "        \n",
    "        # Registrar la consulta y la respuesta en la base de datos\n",
    "        insertar_consulta_respuesta(command, response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear la base de datos y la tabla si no existe\n",
    "    crear_base_datos()\n",
    "\n",
    "    # Ejecutar el asistente de voz\n",
    "    voice_assistant()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Soy tu asistente de voz. (di 'adiós' para terminar la conversación)\n",
      "Escuchando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tú: hola me das unos consejos para el dolor de\n",
      "Asistente: ¡Me alegro de que te rías!\n",
      "Escuchando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tú: suponiendo que eres un doctor qué recomendaciones me das para la fiebre\n",
      "Asistente: !! translated\n",
      "Escuchando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tú: me puedes dar consejos para la fiebre\n",
      "Asistente: El amor no está entre mis habilidades.\n",
      "Escuchando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tú: eres un médico y quiero que me des consejos saludables\n",
      "Asistente: Creo haberte hecho una pregunta.! !! hasta mañana! neto! lunar. net! bla blanca! solitario!\n",
      "Escuchando...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 85\u001B[0m\n\u001B[1;32m     82\u001B[0m crear_base_datos()\n\u001B[1;32m     84\u001B[0m \u001B[38;5;66;03m# Ejecutar el asistente de voz\u001B[39;00m\n\u001B[0;32m---> 85\u001B[0m voice_assistant()\n",
      "Cell \u001B[0;32mIn[2], line 66\u001B[0m, in \u001B[0;36mvoice_assistant\u001B[0;34m()\u001B[0m\n\u001B[1;32m     64\u001B[0m chat_history_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 66\u001B[0m     command \u001B[38;5;241m=\u001B[39m listen_command()\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m command \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[2], line 43\u001B[0m, in \u001B[0;36mlisten_command\u001B[0;34m()\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEscuchando...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     42\u001B[0m recognizer\u001B[38;5;241m.\u001B[39madjust_for_ambient_noise(source)\n\u001B[0;32m---> 43\u001B[0m audio \u001B[38;5;241m=\u001B[39m recognizer\u001B[38;5;241m.\u001B[39mlisten(source)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     46\u001B[0m     command \u001B[38;5;241m=\u001B[39m recognizer\u001B[38;5;241m.\u001B[39mrecognize_google(audio, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mes-ES\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/speech_recognition/__init__.py:460\u001B[0m, in \u001B[0;36mRecognizer.listen\u001B[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001B[0m\n\u001B[1;32m    458\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[1;32m    461\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m a\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/speech_recognition/__init__.py:530\u001B[0m, in \u001B[0;36mRecognizer._listen\u001B[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001B[0m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m phrase_time_limit \u001B[38;5;129;01mand\u001B[39;00m elapsed_time \u001B[38;5;241m-\u001B[39m phrase_start_time \u001B[38;5;241m>\u001B[39m phrase_time_limit:\n\u001B[1;32m    528\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 530\u001B[0m buffer \u001B[38;5;241m=\u001B[39m source\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mread(source\u001B[38;5;241m.\u001B[39mCHUNK)\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# reached end of the stream\u001B[39;00m\n\u001B[1;32m    532\u001B[0m frames\u001B[38;5;241m.\u001B[39mappend(buffer)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/speech_recognition/__init__.py:191\u001B[0m, in \u001B[0;36mMicrophone.MicrophoneStream.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread\u001B[39m(\u001B[38;5;28mself\u001B[39m, size):\n\u001B[0;32m--> 191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyaudio_stream\u001B[38;5;241m.\u001B[39mread(size, exception_on_overflow\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/machine_learning/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001B[0m, in \u001B[0;36mPyAudio.Stream.read\u001B[0;34m(self, num_frames, exception_on_overflow)\u001B[0m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_input:\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot input stream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    569\u001B[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001B[0;32m--> 570\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pa\u001B[38;5;241m.\u001B[39mread_stream(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream, num_frames,\n\u001B[1;32m    571\u001B[0m                       exception_on_overflow)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
